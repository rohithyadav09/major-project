{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pneumonia_cnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNTmAwEHlIhyr9gw/4YLlDJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohithyadav09/major-project/blob/main/pneumonia_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDUwknjrq64y"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBebRxMrq_xd"
      },
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "!unzip \\*.zip && rm *.zip\n",
        "print(\"Completed data download.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9y-DVEkrEFa"
      },
      "source": [
        "Traceback (most recent call last):\n",
        "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
        "    from kaggle.cli import main\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
        "    api.authenticate()\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
        "    self.config_file, self.config_dir))\n",
        "IOError: Could not find kaggle.json. Make sure it's located in /content. Or use the environment method.\n",
        "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
        "\n",
        "No zipfiles found.\n",
        "Completed data download."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDVJxwOJrJBT"
      },
      "source": [
        "shutil.rmtree('chest_xray/__MACOSX')\n",
        "shutil.rmtree('chest_xray/chest_xray')\n",
        "os.rename('chest_xray', 'data')\n",
        "print(\"Completed data management.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y26l-8QCrRc1"
      },
      "source": [
        "---------------------------------------------------------------------------\n",
        "FileNotFoundError                         Traceback (most recent call last)\n",
        "<ipython-input-19-980dc1ad1a23> in <module>()\n",
        "----> 1 shutil.rmtree('chest_xray/__MACOSX')\n",
        "      2 shutil.rmtree('chest_xray/chest_xray')\n",
        "      3 os.rename('chest_xray', 'data')\n",
        "      4 print(\"Completed data management.\")\n",
        "\n",
        "/usr/lib/python3.6/shutil.py in rmtree(path, ignore_errors, onerror)\n",
        "    475             orig_st = os.lstat(path)\n",
        "    476         except Exception:\n",
        "--> 477             onerror(os.lstat, path, sys.exc_info())\n",
        "    478             return\n",
        "    479         try:\n",
        "\n",
        "/usr/lib/python3.6/shutil.py in rmtree(path, ignore_errors, onerror)\n",
        "    473         # lstat()/open()/fstat() trick.\n",
        "    474         try:\n",
        "--> 475             orig_st = os.lstat(path)\n",
        "    476         except Exception:\n",
        "    477             onerror(os.lstat, path, sys.exc_info())\n",
        "\n",
        "FileNotFoundError: [Errno 2] No such file or directory: 'chest_xray/__MACOSX'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSqgVbz5recz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.applications import VGG19\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Model \n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3meirokrfjD"
      },
      "source": [
        "img_width, img_height = 128, 128\n",
        "train_data_dir = \"data/train\"\n",
        "validation_data_dir = \"data/val\"\n",
        "test_data_dir = \"data/test\"\n",
        "NB = 2\n",
        "BS = 64\n",
        "EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PH1fShcrkgI"
      },
      "source": [
        "TRAIN = len(list(paths.list_images(train_data_dir)))\n",
        "VAL = len(list(paths.list_images(validation_data_dir)))\n",
        "TEST = len(list(paths.list_images(test_data_dir)))\n",
        "\n",
        "trainAug = ImageDataGenerator(rescale = 1./255,\n",
        "                    fill_mode = \"nearest\")\n",
        "\n",
        "valAug = ImageDataGenerator(rescale = 1./255,\n",
        "                            fill_mode = \"nearest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCGchi3Froz9"
      },
      "source": [
        "trainGen = trainAug.flow_from_directory(\n",
        "                    train_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = True,\n",
        "                    class_mode = \"categorical\")\n",
        "\n",
        "valGen = valAug.flow_from_directory(\n",
        "                    validation_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = False,\n",
        "                    class_mode = \"categorical\")\n",
        "\n",
        "testGen = valAug.flow_from_directory(\n",
        "                    test_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = False,\n",
        "                    class_mode = \"categorical\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0FO2BvirupP"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.applications import VGG19\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Model \n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# defining constants and variables\n",
        "img_width, img_height = 128, 128\n",
        "train_data_dir = \"data/train\"\n",
        "validation_data_dir = \"data/val\"\n",
        "test_data_dir = \"data/test\"\n",
        "NB = 2\n",
        "BS = 64\n",
        "EPOCHS = 1\n",
        "\n",
        "\n",
        "# creating train, validation and test data generators\n",
        "TRAIN = len(list(paths.list_images(train_data_dir)))\n",
        "VAL = len(list(paths.list_images(validation_data_dir)))\n",
        "TEST = len(list(paths.list_images(test_data_dir)))\n",
        "\n",
        "trainAug = ImageDataGenerator(rescale = 1./255,\n",
        "                    fill_mode = \"nearest\")\n",
        "\n",
        "valAug = ImageDataGenerator(rescale = 1./255,\n",
        "                            fill_mode = \"nearest\")\n",
        "\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "                    train_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = True,\n",
        "                    class_mode = \"categorical\")\n",
        "\n",
        "valGen = valAug.flow_from_directory(\n",
        "                    validation_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = False,\n",
        "                    class_mode = \"categorical\")\n",
        "\n",
        "testGen = valAug.flow_from_directory(\n",
        "                    test_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = False,\n",
        "                    class_mode = \"categorical\")\n",
        "\n",
        "\n",
        "# loading pre-trained model, training additional features and saving model\n",
        "base_model = VGG19(weights = \"imagenet\", include_top=False, \n",
        "                   input_shape = (img_width, img_height, 3))\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation = \"relu\")(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(256, activation = \"relu\")(x)\n",
        "x = Dropout(0.2)(x)\n",
        "preds = Dense(NB, activation = \"softmax\")(x)\n",
        "\n",
        "model = Model(base_model.input, preds)\n",
        "\n",
        "for i,layer in enumerate(model.layers):\n",
        "    print(i,layer.name)\n",
        "\n",
        "for layer in model.layers[:16]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[16:]:\n",
        "    layer.trainable=True\n",
        "\n",
        "model.summary()\n",
        "\n",
        "early = EarlyStopping(monitor = 'val_acc', min_delta = 0, \n",
        "                      patience = 10, verbose= 1 , mode = 'auto')\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", \n",
        "                    optimizer = SGD(lr=0.001, momentum=0.9), \n",
        "                    metrics=[\"accuracy\"])\n",
        "\n",
        "H = model.fit_generator(\n",
        "        trainGen,\n",
        "        epochs = EPOCHS,\n",
        "        validation_data = valGen)\n",
        "\n",
        "model.save('model.h5')\n",
        "\n",
        "\n",
        "# generating predictions using model\n",
        "testGen.reset()\n",
        "predictions = model.predict_generator(testGen, steps = (TEST // BS) + 1) \n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(\"Test set accuracy: \" + \n",
        "      str(accuracy_score(testGen.classes, predictions, normalize=True) * 100) \n",
        "      + \"%\") \n",
        "\n",
        "print(classification_report(testGen.classes, predictions,\n",
        "                            target_names=testGen.class_indices.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}